/*
    The `Scene` class represents a scene in a ray tracing engine, containing the camera, objects, and lights. The scene acts as the main container where all elements (camera, objects, lights) interact to generate the final rendered image. The key methods within this class are the constructor, which sets up the scene with default objects and lighting, and the `Render` function, which renders the scene using ray tracing and multi-threading.

    1. **Constructor (`Scene::Scene`)**:
       - **Camera Setup**: 
         - The camera is positioned at `(0.0, -10.0, 0.0)`, facing the origin `(0.0, 0.0, 0.0)`, with the "up" direction along the z-axis `(0.0, 0.0, 1.0)`. 
         - The horizontal size of the camera view is set to `0.25`, and the aspect ratio is set to `16:9` for a widescreen format. 
         - `UpdateCameraGeometry()` is called to finalize the camera's internal parameters (e.g., projection matrix).
         
       - **Object Initialization**: 
         - Three `ObjSphere` objects (spheres) are added to the scene and stored in the `m_objectList`.
         - These objects are transformed using transformation matrices (`GTform`), where each sphere is translated, rotated, and scaled differently:
            - Sphere 1 is translated to `(-1.5, 0.0, 0.0)` and scaled to `(0.5, 0.5, 0.75)`.
            - Sphere 2 is scaled to `(0.75, 0.5, 0.5)`.
            - Sphere 3 is translated to `(1.5, 0.0, 0.0)` and scaled to `(0.75, 0.75, 0.75)`.
         - Each sphere is also assigned a base color:
            - Sphere 1 is colored `(64.0, 0.5, 200.0)`.
            - Sphere 2 is colored `(1.0, 0.5, 0.0)`.
            - Sphere 3 is colored `(1.0, 200.0, 0.0)`.

       - **Light Initialization**: 
         - A `PointLight` is added to `m_lightList`. The light is placed at `(5.0, -10.0, -5.0)` with a color `(1.0, 1.0, 1.0)` representing white light.

    2. **Render Function (`Scene::Render`)**:
       - This method generates the final image by casting rays through each pixel of the image, calculating intersections with objects, and computing lighting effects. It uses multi-threading to parallelize the rendering process, making use of the available CPU cores.
       
       - **Image Setup**: 
         - The `Render` method retrieves the image dimensions (width `xSize` and height `ySize`) from the `waImage` object.
         - The number of available threads is determined using `std::thread::hardware_concurrency()`, which dynamically adjusts rendering performance based on the hardware.

       - **Threading and Ray Casting**:
         - The image is divided into horizontal slices, one for each thread (`chunkSize = xSize / numThreads`). Each thread renders its assigned slice.
         - Each thread casts rays from the camera through the image pixels in its assigned chunk using normalized coordinates (`normX`, `normY`), generated by the `m_camera.GenerateRay()` function.
         
       - **Intersection Testing**:
         - For each ray, the function checks for intersections with all objects in `m_objectList` by calling `TestIntersection` for each object.
         - If an intersection is found, the intersection point, normal, and color are stored. If multiple objects are hit, the closest one is selected.
         
       - **Illumination Calculation**:
         - Once an intersection is detected, the function calculates the lighting using the lights in `m_lightList`. The `ComputeIllumination()` method determines the color and intensity of the light reaching the intersection point based on the surface normal, light direction, and other objects that may obstruct the light (shadows).
         - The final color for the pixel is calculated based on the closest object's color and the intensity of light hitting it.
         - If no intersection occurs, the pixel is set to black (`0.0, 0.0, 0.0`).

       - **Thread Management**:
         - The rendering tasks are distributed among multiple threads. Each thread processes a chunk of the image, and the main thread waits for all worker threads to finish using `t.join()`.

    3. **Multi-threading**:
       - Multi-threading significantly improves performance, especially for large images, by distributing the rendering workload across available CPU cores. Each thread is responsible for rendering a portion of the image, reducing the overall rendering time.

    4. **Usage in Ray Tracing**:
       - This class orchestrates the ray tracing pipeline. Rays are generated from the camera and tested for intersections with objects, and the lighting effects are calculated based on the light sources and surface interactions. The result is an image where each pixel represents the color determined by the ray-object interactions and lighting.

    5. **Summary**:
       - The `Scene` class handles the setup of objects, lights, and the camera. It also manages the rendering process by casting rays from the camera, testing intersections, calculating lighting, and rendering the final image in a multi-threaded environment.
       - Multi-threading is used to accelerate the rendering, dividing the image into chunks processed by separate threads.
       - The class is fundamental to the ray tracing engine, as it brings together all elements and manages their interaction during the rendering process.
*/

#include "scene.hpp"
#include <thread>
#include <vector>

waRT::Scene::Scene() {
    // test stuff
	m_camera.SetPosition(	qbVector<double>{std::vector<double> {0.0, -10.0, -2.0}} );
	m_camera.SetLookAt	( qbVector<double>{std::vector<double> {0.0, 0.0, 0.0}} );
	m_camera.SetUp			( qbVector<double>{std::vector<double> {0.0, 0.0, 1.0}} );
	m_camera.SetHorzSize(0.25);
	m_camera.SetAspect(16.0 / 9.0);
	m_camera.UpdateCameraGeometry();
	 
	m_objectList.push_back(std::make_shared<waRT::ObjSphere> (waRT::ObjSphere()));
	m_objectList.push_back(std::make_shared<waRT::ObjSphere> (waRT::ObjSphere()));
	m_objectList.push_back(std::make_shared<waRT::ObjSphere> (waRT::ObjSphere()));
	 
    m_objectList.push_back(std::make_shared<waRT::ObjectPlane> (waRT::ObjectPlane()));
    m_objectList.at(3) -> m_baseColor = qbVector<double>{std::vector<double> {0.5, 0.5, 0.5}};
    waRT::GTform planeMatrix;
	planeMatrix.SetTransform(qbVector<double>{std::vector<double>{0.0, 0.0, 0.75}},
					         qbVector<double>{std::vector<double>{0.0, 0.0, 0.0}},
					         qbVector<double>{std::vector<double>{4.0, 4.0, 1.0}});
    m_objectList.at(3) -> SetTransformMatrix(planeMatrix);

	waRT::GTform testMatrix1, testMatrix2, testMatrix3;

	testMatrix1.SetTransform(qbVector<double>{std::vector<double>{-1.5, 0.0, 0.0}},
					         qbVector<double>{std::vector<double>{0.0, 0.0, 0.0}},
					         qbVector<double>{std::vector<double>{0.5, 0.5, 0.75}});						
	testMatrix2.SetTransform(qbVector<double>{std::vector<double>{0.0, 0.0, 0.0}},
					         qbVector<double>{std::vector<double>{0.0, 0.0, 0.0}},
					         qbVector<double>{std::vector<double>{0.75, 0.5, 0.5}});
	testMatrix3.SetTransform(qbVector<double>{std::vector<double>{1.5, 0.0, 0.0}},
					         qbVector<double>{std::vector<double>{0.0, 0.0, 0.0}},
					         qbVector<double>{std::vector<double>{0.75, 0.75, 0.75}});
														
	m_objectList.at(0) -> SetTransformMatrix(testMatrix1);
	m_objectList.at(1) -> SetTransformMatrix(testMatrix2);
	m_objectList.at(2) -> SetTransformMatrix(testMatrix3);
	
	m_objectList.at(0) -> m_baseColor = qbVector<double>{std::vector<double>{0.25, 0.5, 0.8}};
	m_objectList.at(1) -> m_baseColor = qbVector<double>{std::vector<double>{1.0, 0.5, 0.0}};
	m_objectList.at(2) -> m_baseColor = qbVector<double>{std::vector<double>{1.0, 0.8, 0.0}};
	
	m_lightList.push_back(std::make_shared<waRT::PointLight> (waRT::PointLight()));
	m_lightList.at(0) -> m_location = qbVector<double> {std::vector<double> {5.0, -10.0, -5.0}};
	m_lightList.at(0) -> m_color = qbVector<double>    {std::vector<double> {1.0, 1.0, 1.0}};
}

bool waRT::Scene::Render(waImage &outputImage) {
    int xSize = outputImage.GetXSize();
    int ySize = outputImage.GetYSize();
    
    int numThreads = std::thread::hardware_concurrency();   
    std::vector<std::thread> threads;

    double xFact = 1.0 / (static_cast<double>(xSize) / 2.0);
    double yFact = 1.0 / (static_cast<double>(ySize) / 2.0);
     
    auto renderChunk = [&](int startX, int endX) {
        waRT::Ray cameraRay;
        qbVector<double> tempIntPoint(3);
        qbVector<double> tempNormal(3);
        qbVector<double> tempColor(3);
        double minDist = 1e6;
        double maxDist = 0.0;

        for (int x = startX; x < endX; x++) {
            for (int y = 0; y < ySize; y++) {
                double normX = (static_cast<double>(x) * xFact) - 1.0;
                double normY = (static_cast<double>(y) * yFact) - 1.0;
                m_camera.GenerateRay(normX, normY, cameraRay);
                std::shared_ptr<waRT::ObjectBase> closestObject; 
                qbVector<double> closestIntPoint{3};    
                qbVector<double> closestNormal  {3};      
                qbVector<double> closestColor   {3};       
                double closestDist = 1e6;          
                bool hitObject = false; 
                for (auto currentObject : m_objectList) {
                    bool validInt = currentObject->TestIntersection(cameraRay, tempIntPoint, tempNormal, tempColor);
                    if (validInt) {
                        hitObject = true;
                        double dist = (tempIntPoint - cameraRay.m_point1).norm();
                        if (dist < closestDist) {
                            closestDist     = dist;
                            closestIntPoint = tempIntPoint;
                            closestNormal   = tempNormal;
                            closestColor    = tempColor;
                            closestObject   = currentObject;
                        }
                    }
                }
                 
                if (hitObject) {
                    double intensity;
                    bool validIllum = false;
                    bool illumFound = false;
                    qbVector<double> color{3};
                    double red = 0.0;
                    double green = 0.0;
                    double blue = 0.0;
                    for (auto currentLight : m_lightList) {
                        validIllum = currentLight->ComputeIllumination(closestIntPoint, closestNormal, m_objectList, nullptr, color, intensity);
                        if (validIllum){
						    illumFound = true;
						    red   += color.GetElement(0) * intensity;
						    green += color.GetElement(1) * intensity;
						    blue  += color.GetElement(2) * intensity;
					    }
                    }
                    if (illumFound) {
                        red   *= closestColor.GetElement(0);
                        green *= closestColor.GetElement(1);
                        blue  *= closestColor.GetElement(2);
                        outputImage.SetPixel(x, y, red, green, blue);
                    }
                } 
            }
        }
        std::cout << "Thread completed rendering from X=" << startX << " to X=" << endX << std::endl;
    };

    int chunkSize = xSize / numThreads;   

    for (int i = 0; i < numThreads; ++i) {
        int startX = i * chunkSize;
        int endX   = (i == numThreads - 1) ? xSize : (i + 1) * chunkSize;   
        threads.emplace_back(renderChunk, startX, endX);   
    }
    for (auto &t : threads) { t.join();}
    return true;
}
